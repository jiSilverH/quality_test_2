# 역량평가 정리

### 문제9

자연어처리 모델 관련 설명으로 옳은 것 고르기

## 0. GPT

- Transformer decoder 구조
- 각 블록:
    1. Masked Multi-Head Self-Attention
    2. Feed-Forward Network (FFN)
    3. Layer Normalization & Residual Connection
- **사전 학습 목표**: 이전 토큰들을 기반으로 다음 토큰 확률 분포를 예측 (언어모델링)
- 다음에 올 단어를 예측하는 방식으로 사전 학습 수행 → cross-entropy loss 사용

## **1. BERT (Bidirectional Encoder Representations from Transformers)**

- **구조**: Transformer **Encoder**만 사용 (양방향 문맥 학습)
- **사전 학습 방법**
    1. **Masked Language Modeling (MLM)**
        - 입력 토큰의 일부를 `[MASK]`로 가리고 원래 단어 예측
        - 양방향 문맥 정보 사용 가능
    2. **Next Sentence Prediction (NSP)**
        - 두 문장이 순서상 이어지는지(True) 또는 무작위 조합(False)인지 분류
- **장점**: 문장 내·문장 간 관계 모두 학습 가능
- **한계**: MLM 시 [MASK] 토큰이 실제 사용 환경과 불일치(노이즈)

---

## **2. SpanBERT**

- **목표**: **연속된 구간(Span)** 단위 예측 성능 강화
- **변경점**
    - MLM 대신 **Span Masking** 사용
        
        → 임의의 연속된 토큰 구간을 가려서 구간 전체를 예측
        
    - **Span Boundary Objective**: 구간 양 끝의 representation을 통해 내부 토큰 복원
- **장점**: 개체명 인식, 질의응답(QA)처럼 **연속 구간 예측** 태스크에서 BERT보다 우수

---

## **3. RoBERTa (Robustly Optimized BERT)**

- **개선 포인트**
    1. NSP 제거 → 오히려 성능 향상
    2. 학습 데이터와 배치 크기, 학습 시간 **대폭 증가**
    3. Dynamic Masking → 매 epoch마다 다른 마스킹 패턴 적용 = 데이터를 로딩할 때마다 마스킹 위치를 바꾸는 것을 의미
        1. bert는 static masking임
    4. 더 긴 시퀀스 길이로 학습
- **효과**: 동일 구조로 BERT보다 성능 향상

---

## **4. ELECTRA**

- **아이디어**: "토큰 예측" 대신 "진짜 vs 가짜" 판별
- **Generator–Discriminator 구조**
    1. **Generator**: MLM 방식으로 가짜 토큰 생성
    2. **Discriminator**: 각 **토큰**이 원래 진짜였는지(Real) 아니면 Generator가 만든 가짜인지(Fake) 판별
- **장점**
    - 모든 토큰에서 학습 신호 제공 (MLM보다 효율적)
    - 더 적은 계산량으로도 BERT 수준·이상의 성능

## **5. BART (Bidirectional and Auto-Regressive Transformers)**

### 1. 구조 개요

- **Transformer 기반 Encoder–Decoder 구조**
    - **Encoder**: BERT처럼 **양방향** 문맥 이해
    - **Decoder**: GPT처럼 **왼쪽에서 오른쪽**(Auto-regressive) 생성
- 입력을 **다양한 노이즈로 변형**한 후, 원래 문장을 복원하는 방식으로 학습

---

### 2. 사전 학습 방식 (Denoising Autoencoder)

BART는 원문 → **노이즈 추가** → 복원하는 과정을 학습

- **노이즈 유형**
    1. **Token Deletion**: 토큰 제거; 무작위로 토큰을 삭제하는 방법, 모델은 어디에서 토큰이 누락되었는지를 결정해야함
    2. **Text Infilling**: 연속된 구간을 마스킹, 각 span에서 얼마만큼의 토큰들이 없어졌는지를 학습
    3. **Sentence Permutation**: 문장 순서 섞기
    4. **Token Masking**: 일부 토큰을 `[MASK]`로 바꿈
    5. **Document Rotation**: 문서 시작 위치를 바꿈
- **목표**: Decoder가 원래 문장을 재구성

---

### 3. 특징

- **다목적성**: 요약, 번역, 질의응답, 문장 생성 모두 가능
- **장점**
    - Encoder 덕분에 입력 전체의 양방향 이해
    - Decoder 덕분에 문장 생성 능력 우수
    - 다양한 노이즈 덕분에 복원·생성 능력 강화
- **활용 예시**:
    - 요약(Summarization)
    - 데이터 복원(에러 수정)
    - 자연스러운 텍스트 생성

---

### 4. 다른 모델과 비교

| 모델 | 구조 | 학습 방식 | 주요 특징 |
| --- | --- | --- | --- |
| **BERT** | Encoder만 | MLM + NSP | 이해 중심 |
| **GPT** | Decoder만 | Auto-regressive LM | 생성 중심 |
| **BART** | Encoder-Decoder | Denoising Autoencoder | 이해 + 생성 둘 다 가능 |

### 문항10

LoRA (Row-rank Adaptation)

- LLM의 파라미터 효율성을 향상시키기 위해, 전체 가중치 행렬을 직접 수정하는 대신, 두 개의 저차원 행렬 A와 행렬 B를 사용
- 이 행렬들은 사전 훈련된 모델의 각 transformer layer에 삽입되어, A와 B의 곱 BA가 원래의 가중치 W_0에 더해져서, 가중치의 변화 delta_W를 모델링한다.
- 이 저차원 곱셈은 본질적으로 모델의 표현력을 증가시키면서도 파라미터 수는 상대적으로 적게 증가시켜, 전체 모델의 파라미터를 크게 늘리지 않고도 특정 작업에 더 효과적으로 적응할 수 있도록 돕는다

## **LoRA (Low-Rank Adaptation)**

### 1. 개념

- **대규모 모델의 모든 파라미터를 업데이트하지 않고**, 일부 가중치 행렬을 **저차원(낮은 rank) 행렬 분해** 형태로 학습하는 기법
- 원래 모델 파라미터는 **동결(freeze)**, 새로 추가한 LoRA 모듈만 학습

---

### 2. 동작 원리

- Transformer의 **Attention 가중치 행렬 W**를 직접 업데이트하지 않음
- 대신 **W + ΔW** 형태로 쓰되,
    - ΔW = **A × B**
    - A, B는 rank가 낮은(작은 차원의) 학습 가능 행렬
- 수식:
    
    ```
    y = Wx
    y' = (W + BA)x
    
    ```
    
    - W: 원래 모델의 고정된 가중치
    - B, A: 학습되는 작은 행렬 (rank r, r << dimension)

---

### 3. 장점

1. **파라미터 효율**: 학습해야 하는 파라미터 수가 매우 적음 → 메모리 절약
2. **저장·배포 용이**: LoRA 모듈만 저장하면 됨 (원본 모델 공유 가능)
3. **성능 유지**: 풀 파인튜닝에 가까운 성능
4. **다중 태스크 전환**: 하나의 모델에 여러 LoRA 모듈을 붙여 쉽게 태스크 변경 가능

---

### 4. 사용 예시

- **대규모 언어 모델(LLM)** → GPT, LLaMA, BLOOM, Falcon 등 파인튜닝
- **멀티태스크 학습** → 각 태스크마다 LoRA 모듈 따로 저장
- **경량 디바이스**에서의 파인튜닝 → VRAM 적은 GPU에서도 가능

### 문항11

## 0. CAM (class activation mapping)

## **1. 개념**

- CNN 기반 분류 모델이 특정 클래스를 예측할 때, **이미지의 어느 부분이 중요한지**를 보여주는 기술
- **클래스별 활성화 지도(Class Activation Map)** 생성
- 주로 **모델 해석(Explainability)**, **모델 신뢰성 평가** 등에 사용

---

## **2. 원리 (CAM, 원래 방식)**

![image.png](%EC%97%AD%EB%9F%89%ED%8F%89%EA%B0%80%20%EC%A0%95%EB%A6%AC%2024f4d6b253d380f4a698df83390921af/image.png)

- 구조 전제: **Global Average Pooling (GAP)** + **FC Layer(분류기)**
- 과정:
    1. **마지막 합성곱(Conv) 레이어**에서 feature map f_k(x, y) 추출
        - k: 채널 인덱스
    2. GAP을 적용하여 채널별 평균값 F_k 계산
    3. Fully Connected Layer의 클래스별 가중치 w_{c,k} 사용
    4. 특정 클래스 c에 대한 CAM 계산:Mc(x,y)=k∑wc,k⋅fk(x,y)
        
        Mc(x,y)=∑kwc,k⋅fk(x,y)M_c(x, y) = \sum_k w_{c,k} \cdot f_k(x, y)
        
    5. McM_cMc를 원본 이미지 크기로 보간 → 시각화
- **GAP will calculate a single value for an entire feature map**

---

## **3. 한계**

- **GAP + FC 구조**여야만 적용 가능
- 구조 제약 때문에 ResNet, EfficientNet 등 일반 구조에 바로 적용 어려움 → 이후 **Grad-CAM** 같은 변형 기법 등장

---

## **4. 변형 기법 예시**

- **Grad-CAM**: 구조 제약 없이 사용 가능, gradient를 활용해 중요도 계산
- **Score-CAM**: gradient 없이 score 변화를 기반으로 중요도 계산

---

## **5. 활용 분야**

- 모델 해석 및 디버깅
- 의료 영상 분석(병변 위치 확인)
- 객체 인식 모델 시각화
- 데이터셋 오류 탐지

---

📌 **암기 팁**

- CAM = **(FC Layer weight) × (Feature map)**
- GAP 필수 → 구조 제한
- 변형: Grad-CAM(gradient), Score-CAM(score 변화)

## **1. Grad-CAM (Gradient-weighted Class Activation Mapping)**

### 개념

- **CAM의 구조적 제약**(GAP+FC 필요)을 없앤 버전
- **Gradient**를 이용해 마지막 Convolution Layer의 feature map 채널별 중요도를 계산
    - 각 feature map의 모든 원소를 미분한 것을 더한 다음 전체 크기로 나눠 각 feature map에 대한 gradient를 구함
    - 이 gradient를 가중 합하여
- CNN, ResNet, VGG, Inception 등 대부분의 구조에 적용 가능
- **feature map(특징맵)에 대한 손실함수(loss function)에 대한 기울기를 기반**으로 특징맵의 중요도를 구하는 방법

### 원리

![image.png](%EC%97%AD%EB%9F%89%ED%8F%89%EA%B0%80%20%EC%A0%95%EB%A6%AC%2024f4d6b253d380f4a698df83390921af/image%201.png)

### 특징

- 구조 제약 없음
- Gradient 기반이므로 **역전파 필요**
- ReLU 사용 → 양의 기여만 강조

---

## **2. Score-CAM**

### 개념

- Gradient 사용 없이 **출력 score 변화**를 기반으로 중요도 계산
- CAM의 noise 문제와 Grad-CAM의 gradient 의존성 문제 완화

### 원리

![image.png](%EC%97%AD%EB%9F%89%ED%8F%89%EA%B0%80%20%EC%A0%95%EB%A6%AC%2024f4d6b253d380f4a698df83390921af/image%202.png)

### 특징

- Gradient 불필요 → 백프로퍼게이션 없이 가능
- 계산량 많음 (채널 수만큼 forward 필요)
- 노이즈 적고 안정적

---

## **3. 비교 요약 표**

| 항목 | Grad-CAM | Score-CAM |
| --- | --- | --- |
| **Gradient 필요** | ✔ 필요 | ✘ 불필요 |
| **계산량** | 적음 | 많음 (채널 수 × forward) |
| **노이즈** | 다소 있음 | 적음 |
| **적용 구조** | 제약 없음 | 제약 없음 |
| **원리** | gradient로 채널 가중치 | score 변화로 채널 가중치 |

---

📌 **암기 팁**

- **Grad-CAM** = gradient로 가중치 → 빠름, noise 가능
- **Score-CAM** = score 변화로 가중치 → 느림, noise 적음

### 문항12

XAI

**Logistic regression**

![image.png](%EC%97%AD%EB%9F%89%ED%8F%89%EA%B0%80%20%EC%A0%95%EB%A6%AC%2024f4d6b253d380f4a698df83390921af/image%203.png)

| 항목 | Linear Regression | Logistic Regression |
| --- | --- | --- |
| 목적 | 연속형 값 예측 | 이진 분류 확률 예측 |
| 출력 범위 | −∞-\infty ~ +∞+\infty | 0 ~ 1 |
| 활성 함수 | 없음 | Sigmoid |
| 손실 함수 | MSE | Cross-Entropy |
| 출력 해석 | 예측값 그대로 사용 | 확률로 해석, 임계값 적용 |

📌 **한 줄 요약**

- Linear Regression: "그냥 선형 방정식" → 값 그대로 예측
- Logistic Regression: "선형 방정식 + Sigmoid" → 확률로 변환해 분류

- Surrogate 모델
    - 복잡한 시스템이나 모델을 대신하여 근사치를 제공하는 보조 모델
    - 블랙박스 모델의 예측을 해석하고 이해하는 데에 도움을 줌 → 블랙박스 모델의 동작을 보다 쉽게 이해 가능!
    

### 문항17

### 1. **Model-in-Service**

- **정의**: 모델이 특정 서비스(혹은 애플리케이션)의 일부로 내장되어 운영되는 방식입니다.
- **특징**:
    - 예: 웹 애플리케이션 내 특정 트래픽 예측, 추천 시스템 등의 기능이 서비스 코드 내부에 직접 포함된 형태.
    - 모델 배포와 서비스 운영이 결합되어 있음. 유지, 버전 관리, 확장 책임이 서비스 개발자에게 있음.
    - 전형적으로 “서비스 레이어” 혹은 API 서버 내부에 포함되어 동작합니다.
    
    *비슷한 맥락에서 “Model”과 “Service” 차이를 MVC 기준으로 보면:*
    
    모델(Model)은 데이터 구조와 연산을 담당하고, 서비스(Service)는 모델과 연관된 다양한 작업을 수행하는 역할을 합니다. 예를 들어, `EmployeeService::hireEmployee`는 채용 절차 전반(모델 인스턴스 생성, 이메일 발송 등)을 처리하죠.
    

---

### 2. **Model-as-a-Service (MaaS)**

- **정의**: 기계 학습(Machine Learning) 또는 AI 모델을 클라우드 기반으로 호스팅하고, API를 통해 외부에서 **서비스 형태로 제공**하는 모델 제공 방식입니다.
- **특징**:
    - 사전 학습된 ML 모델을 API 형태로 제공 → 호출만 하면 예측 결과를 받을 수 있음.
    - 인프라, 배포, 확장, 운영은 모델 제공자(서비스) 측에서 관리.
    - AI/ML 기능을 빠르게 도입하고 싶은 조직에 적합하며, 비용 절감, 확장성, 접근성을 동시에 확보할 수 있음.
    - “X-as-a-Service”의 일종으로, SaaS나 PaaS처럼 사용량 기반 구독 모델로 제공되는 클라우드형 AI 서비스입니다.
- **출처별 설명**:
    - Azure 설명에서는, MaaS는 사전 학습된 ML 모델에 대한 "클라우드 기반 API 액세스" 형태이며, AI 기능을 빠르게 App에 통합할 수 있게 해준다고 강조합니다.[Microsoft Azure](https://azure.microsoft.com/en-us/resources/cloud-computing-dictionary/what-is-models-as-a-service-maas?utm_source=chatgpt.com)
    - Red Hat은 MaaS를 “조직 내부에서 모델을 팀, 애플리케이션 단위로 온디맨드로 제공할 수 있게 하는 공유 리소스”로 정의합니다. 또한 하이브리드 클라우드 환경, API 게이트웨이, 추적·관리를 위한 시스템 구성도 포함된다고 합니다.[Red Hat](https://www.redhat.com/en/topics/ai/what-is-models-as-a-service?utm_source=chatgpt.com)
    - GenAI 시대에 MaaS는 AI 모델 사용을 민주화하고 인프라 부담 없이 AI를 활용하게 만드는 중요한 패러다임이라는 점도 언급됩니다.[ResearchGate+4arXiv+4Microsoft Azure+4](https://arxiv.org/abs/2311.05804?utm_source=chatgpt.com)

---

## 요약 비교표

| 구분 | Model-in-Service | Model-as-a-Service (MaaS) |
| --- | --- | --- |
| **위치 / 통합 방식** | 서비스 코드 내부에 통합 | 독립적 API 형태로 외부 제공 |
| **관리 책임** | 애플리케이션 개발자가 담당 | 모델 제공자/플랫폼에서 담당 |
| **확장성 및 인프라** | 개발자가 직접 확장/운영 | 클라우드 기반으로 자동 확장 |
| **사용자 접근 방식** | 내부 사용 목적 위주 | 내부외부 누구나 API 호출 가능 |
| **적합 대상** | 특정 기능에 통합된 모델 | AI 기능을 빠르게 도입하고 싶은 조직 |

### 문항 19

## **1. Zero-Shot Learning (ZSL)**

- **정의**: 학습에서 **본 적 없는 클래스**에 대해 예측
- **방법**: 클래스의 **설명(텍스트)**, **속성(attribute)**, 또는 **의미론적 임베딩**을 사용
- **예시**: “얼룩말” 이미지를 본 적 없지만, “줄무늬가 있는 말”이라는 속성 설명을 이용해 분류
- **특징**:
    - 라벨 데이터 없이 새로운 클래스를 다룰 수 있음
    - 클래스 설명 품질에 따라 성능 좌우됨

---

## **2. One-Shot Learning**

- **정의**: 새로운 클래스당 **1개의 샘플**만 보고 학습/추론
- **방법**: 주로 **metric learning** 또는 **Siamese network**를 사용해 이미지 간 유사도 계산
- **예시**: 신분증 인식 시스템에서, 특정 사람의 사진 1장만으로 그 사람을 인식
- **특징**:
    - 데이터가 매우 제한된 환경에서 유용
    - 일반화 능력이 중요

---

## **3. Few-Shot Learning (FSL)**

- **정의**: 새로운 클래스당 **소량(수~수십 개)의 샘플**로 학습
- **방법**: Meta-Learning, Prompt-based Learning 등 사용
- **예시**:
    - 5개의 고양이 품종 사진을 보고 품종 분류 학습
- **특징**:
    - ZSL보다 데이터가 조금 더 있음
    - 대규모 사전학습 모델을 활용하면 효과 ↑

---

## **4. Generalized Zero-Shot Learning (GZSL)**

- **정의**: 테스트 시 **본 적 있는 클래스(Seen)** + **본 적 없는 클래스(Unseen)**를 **모두** 구분해야 하는 설정
    
    → zero-shot learning보다 더 실제적인 시나리오에 가까움, 모델의 일반화 능력을 크게 향상 가능
    
- **차이점**:
    - ZSL은 “Unseen 클래스만” 분류
    - GZSL은 Seen/Unseen 모두 예측해야 하므로, Seen 클래스 쏠림(bias) 문제 발생
- **예시**:
    - 학습: 고양이, 개 (Seen)
    - 테스트: 고양이, 개, 호랑이, 얼룩말 (Seen+Unseen)

---

## **5. 비교 표**

| 구분 | 학습 시 새로운 클래스 데이터 | 테스트 시 | 예시 |
| --- | --- | --- | --- |
| **Zero-Shot** | 없음 | Unseen만 | “줄무늬 말” 설명 듣고 얼룩말 맞히기 |
| **One-Shot** | 1개 | 그 클래스 예측 | 사진 1장 보고 인물 인식 |
| **Few-Shot** | 소량(2~수십 개) | 그 클래스 예측 | 5장 보고 품종 분류 |
| **GZSL** | 없음 | Seen+Unseen 모두 | 고양이·개·얼룩말 모두 분류 |

---

📌 **암기 팁**

- **데이터 양**: Zero < One < Few
- **GZSL**: ZSL 확장판 + Seen 포함 → bias 조정 필요
- **One-Shot/Few-Shot**: 새로운 클래스에 적은 데이터 제공
- **Zero-Shot**: 새로운 클래스에 데이터 자체 없음, 대신 설명/속성 사용

### 문항 21

# 1. NAS: AI가 AI를 설계하다

NAS는 쉽게 말해 'AI가 AI를 설계하는 기술'입니다. 지금까지 AI 모델의 구조(아키텍처)를 설계하는 것은 전문가들의 영역이었습니다. 이들은 마치 건축가가 건물을 설계하듯 AI 모델의 각 층과 연결 구조를 세심하게 계획했죠. 하지만 NAS는 이 과정을 자동화합니다.

예를 들어, 이미지 인식을 위한 AI 모델을 만든다고 생각해봅시다. 전문가라면 수작업으로 여러 층의 신경망을 쌓고, 필터 수, 커널 크기 등 각 층의 특성을 결정해야 합니다. 반면 NAS는 이 모든 과정을 자동으로 수행합니다. AI가 스스로 최적의 신경망 구조를 찾아내는 것이죠.

# 2. NAS의 작동 원리: 3단계 프로세스

NAS의 작동 원리는 크게 세 단계로 나눌 수 있습니다:

# 1) 탐색 공간 정의

탐색 공간 정의 단계에서는 AI 모델에 사용할 수 있는 모든 구성 요소(예: 합성곱 층, 풀링 층, 완전 연결 층 등)와 그들 간의 가능한 모든 조합을 정의합니다. 이는 NAS가 탐색할 '가능성의 우주'를 만드는 과정이라고 볼 수 있습니다.

# 2) 탐색 전략

다음 단계에서는 정의된 탐색 공간에서 최적의 구조를 찾는 방법을 결정합니다. 주로 사용되는 방법으로는 강화학습, 진화 알고리즘, 그라디언트 기반 최적화 등이 있습니다. 예를 들어, 강화학습을 사용한다면 AI는 모델 구조를 하나씩 '시도'해보고, 그 결과에 따라 보상을 받습니다. 좋은 성능을 내는 구조에 대해서는 높은 보상을 받고, 이를 바탕으로 더 나은 구조를 탐색해 나갑니다.

# 3) 성능 추정 전략

찾아낸 구조의 성능을 평가합니다. 모든 구조를 완전히 학습시키고 평가하는 것은 시간이 너무 오래 걸리기 때문에, 주로 부분 학습이나 파라미터 공유 등의 기법을 사용하여 빠르게 성능을 추정합니다.

# 3. NAS의 장점과 차별점

# 1) 효율성과 규모

NAS는 인간 전문가보다 훨씬 더 많은 구조를 빠르게 탐색할 수 있습니다. 24시간 쉬지 않고 일하는 AI 설계자라고 생각해보세요. 인간이 몇 달 혹은 몇 년에 걸쳐 시도해볼 수 있는 것보다 훨씬 더 많은 가능성을 단시간 내에 탐색할 수 있습니다.

# 2) 새로운 발견과 혁신

인간의 편견이나 기존 관행에 구애받지 않기 때문에, NAS는 인간이 미처 생각하지 못한 혁신적인 구조를 발견할 가능성이 있습니다. 실제로 NAS를 통해 발견된 몇몇 구조들은 인간 전문가들이 놀랄 만한 성능을 보여주었습니다.

# 3) 복잡성 관리

현대의 AI 모델은 매우 복잡하여 수백, 수천 개의 층과 수백만 개의 파라미터를 가질 수 있습니다. NAS는 이러한 복잡성을 효과적으로 관리하고, 인간이 직관적으로 파악하기 어려운 복잡한 상호작용을 고려할 수 있습니다.

# 4) 동적 적응성

NAS는 새로운 데이터나 요구사항에 따라 모델 구조를 동적으로 조정할 수 있습니다. 이는 변화하는 환경이나 데이터 특성에 빠르게 대응할 수 있게 해줍니다.

# 5) 다중 목표 최적화

NAS는 정확도, 속도, 메모리 사용량 등 여러 목표를 동시에 고려하여 최적화할 수 있습니다. 이는 인간이 수동으로 하기에는 매우 복잡한 작업입니다.

# 6) 자동화와 접근성

NAS는 AI 모델 설계 과정을 자동화함으로써, AI 전문가가 아닌 사람들도 고성능 AI 모델을 개발할 수 있게 해줍니다. 이는 AI 기술의 민주화와 접근성 향상에 기여합니다.

# 4. NAS의 도전과제: 앞으로 해결해야 할 문제들

# 1) 계산 효율성과 확장성

NAS의 가장 큰 도전 중 하나는 엄청난 계산 비용입니다. 최신 연구에서는 이를 해결하기 위해 다양한 접근법이 시도되고 있습니다. 진화적 알고리즘과 베이지안 최적화를 결합한 하이브리드 방식, 신경망 가지치기와 양자화 기법을 NAS 과정에 통합하는 방법, 그리고 메타러닝을 활용한 효율적인 아키텍처 탐색 등이 그 예입니다. 그러나 이러한 방법들도 대규모 문제에 적용할 때 여전히 한계가 있어 계산 효율성과 확장성 개선은 지속적인 연구 과제입니다.

# 2) 다중 목표 최적화의 복잡성

지연 시간, 에너지 효율성, 메모리 사용량 등 여러 목표를 동시에 고려하는 다중 목표 최적화는 매우 복잡한 문제입니다. 파레토 최적 해집합 탐색의 어려움, 목표 간 트레이드오프를 정량화하는 방법, 동적으로 변화하는 환경에서의 다중 목표 최적화 등이 주요 과제로 남아 있습니다.

# 3) 탐색 공간의 표현력과 효율성

효과적인 탐색 공간 설계는 NAS의 성능을 좌우하는 핵심 요소입니다. 충분한 표현력과 탐색 효율성 사이의 균형, 도메인 지식을 탐색 공간에 효과적으로 통합하는 방법, 새로운 연산자나 구조를 동적으로 탐색 공간에 추가하는 방법 등이 중요한 연구 주제입니다.

# 4) 설명 가능성과 해석 가능성

NAS로 생성된 모델의 구조와 동작 원리를 이해하고 설명하는 것은 중요한 과제입니다. 복잡한 NAS 모델의 의사결정 과정 해석, NAS 과정 자체의 투명성 확보, 규제 및 윤리적 측면에서의 설명 가능성 요구 충족 등이 이에 해당합니다.

# 5) 전이 학습과 일반화 능력

특정 태스크나 데이터셋에 최적화된 NAS 모델의 일반화 능력 향상은 중요한 연구 주제입니다. 다양한 도메인 간 지식 전이 메커니즘 개발, 제로샷 또는 퓨샷 학습 능력을 갖춘 NAS 모델 설계, 지속적 학습을 지원하는 NAS 프레임워크 개발 등이 이에 포함됩니다.

# 6) 편향성과 공정성 문제

NAS 과정에서 발생할 수 있는 알고리즘 편향성과 불공정성 문제도 중요한 도전 과제입니다. 훈련 데이터의 편향이 NAS 결과에 미치는 영향 분석, 공정성을 명시적 목표로 하는 NAS 알고리즘 개발, 다양한 인구 통계학적 그룹에 대해 공평한 성능을 보이는 모델 설계 등이 이에 해당합니다.

**DARTS (Differentiable Architecture Search)**

## 1. 개념

- *NAS(Neural Architecture Search)**의 한 방법
- 기존 NAS는 아키텍처 탐색을 **이산(discrete)** 공간에서 수행 → **미분 불가능** → 강화학습(RL)이나 진화 알고리즘처럼 계산량이 큰 방법 사용
- **DARTS**는 이산 선택을 **연속 공간**으로 완화(continuous relaxation)하여 **경사 하강법(gradient descent)**으로 최적화 가능하게 만든 방법
- 논문: *Liu et al., 2018, "DARTS: Differentiable Architecture Search"*

---

## 2. 핵심 아이디어

1. **Search Space 연속화**
    - 각 연산(예: 3×3 conv, 5×5 conv, skip connection 등)을 **softmax로 가중치 합** 형태로 표현
    - 예:o(i,j)(x)=k∑∑k′exp(αk′(i,j))exp(αk(i,j))⋅opk(x)
        
        o(i,j)(x)=∑kexp⁡(αk(i,j))∑k′exp⁡(αk′(i,j))⋅opk(x)o^{(i,j)}(x) = \sum_{k} \frac{\exp(\alpha_k^{(i,j)})}{\sum_{k'}\exp(\alpha_{k'}^{(i,j)})} \cdot op_k(x)
        
        여기서 α\alphaα가 학습 가능한 아키텍처 파라미터
        
2. **2단계 최적화(Bi-level optimization)**
    - **모델 파라미터 www**: 훈련 데이터로 학습
    - **아키텍처 파라미터 α\alphaα**: 검증 데이터로 학습
3. 탐색이 끝나면, softmax 가중치에서 가장 큰 연산을 선택해 **이산 아키텍처**로 변환

---

## 3. 장점

- **계산 효율성**: RL/진화 기반 NAS보다 훨씬 빠름
- **미분 가능성**: 표준 딥러닝 프레임워크(PyTorch, TensorFlow)에서 쉽게 구현 가능
- **경험적 성능**: 이미지 분류(CIFAR-10, ImageNet) 등에서 좋은 성능 달성

---

## 4. 한계

- **연속 완화로 인한 bias**: 실제 discrete 선택과 학습 중 softmax 혼합이 다를 수 있음
- local minima 문제 발생 가능
- memory 사용량 증가(모든 후보 연산을 동시에 계산)

---

## 5. 응용

- 이미지 분류, 시계열 분석, NLP 모델 아키텍처 탐색
- 다양한 변형 기법 존재(PC-DARTS, Fair-DARTS, RobustDARTS 등)

---

📌 **암기 포인트**

> “DARTS = NAS를 미분 가능하게 만든 방법, discrete → continuous, gradient descent로 빠른 탐색”
> 

**Q-learning**

## 1. 개념

- *강화학습(RL)**의 대표적인 **값 기반(Value-based)** 알고리즘
- “어떤 상태에서 어떤 행동을 했을 때 얻을 수 있는 **장기적인 보상**”을 **Q값(Q-value)**으로 표현
- Q값을 테이블 형태로 저장하고 업데이트하면서 **최적 정책**(Optimal Policy)을 학습

---

## 2. 핵심 아이디어

- **Q(s, a)**: 상태 sss에서 행동 aaa를 했을 때 얻는 **누적 보상 기대값**
- **목표**: Q값을 점점 더 정확하게 추정해, 매 상황에서 Q값이 가장 큰 행동 선택
- **업데이트 규칙** (벨만 방정식 기반):

Q(s,a)←Q(s,a)+α[r+γmax⁡a′Q(s′,a′)−Q(s,a)]Q(s,a) \leftarrow Q(s,a) + \alpha \big[ r + \gamma \max_{a'} Q(s',a') - Q(s,a) \big]

Q(s,a)←Q(s,a)+α[r+γa′maxQ(s′,a′)−Q(s,a)]

- α\alphaα: 학습률
- rrr: 현재 행동으로 받은 보상
- γ\gammaγ: 미래 보상 할인율
- s′s's′: 다음 상태
- a′a'a′: 다음 상태에서 가능한 행동들

---

## 3. 동작 절차

1. **Q 테이블 초기화** (모든 상태-행동 쌍의 Q값을 0으로 시작)
2. **에이전트가 환경에서 행동** 선택 (탐험 vs 활용, e.g. ε-greedy 정책)
3. **보상 r과 다음 상태 s′ 관찰**
4. **Q값 업데이트** (위 수식 사용)
5. 목표: Q값이 수렴하면, 각 상태에서 Q값이 최대인 행동을 선택 → 최적 정책 완성

---

## 4. 특징

- **모델 프리(model-free)**: 환경의 전이 확률, 보상 분포를 몰라도 학습 가능
- 상태·행동 공간이 **작을 때** 효율적
- **단점**: 상태/행동이 많거나 연속 공간이면 Q 테이블이 너무 커짐 → DQN 같은 신경망 기반으로 확장 필요

---

## 5. 간단 예시

**미로 탈출 게임**

- 상태 s: 에이전트 위치
- 행동 a: 상, 하, 좌, 우
- 보상 r: 출구에 도달하면 +10, 벽 부딪히면 -1
- Q-learning은 여러 에피소드를 거치며 각 위치-행동의 Q값을 업데이트해, 결국 출구로 가는 최적 경로를 학습

---

📌 **암기 포인트**

> Q-Learning = “상태-행동 가치(Q)를 테이블에 저장하고, 벨만 방정식으로 업데이트하는 값 기반 RL”
> 

**Deep Q-Network**

## 1. 개념

- **Deep Q-Learning**의 한 형태
- Q-Learning(값 기반 RL)의 Q-함수를 **신경망**으로 근사하는 방법
- Google DeepMind가 2015년 발표 (*Mnih et al., Nature 2015*)
- Atari 게임 등에서 **픽셀 입력만으로 인간 수준 성능** 달성

---

## 2. 핵심 아이디어

1. **Q-Learning** 복습
    - Q(s, a): 상태 s에서 행동 a를 했을 때의 장기적 보상 기대값
    - 벨만 방정식(Bellman Equation) 기반 업데이트:Q(s,a)←Q(s,a)+α[r+γa′maxQ(s′,a′)−Q(s,a)]
        
        Q(s,a)←Q(s,a)+α[r+γmax⁡a′Q(s′,a′)−Q(s,a)]Q(s,a) \leftarrow Q(s,a) + \alpha [r + \gamma \max_{a'} Q(s',a') - Q(s,a)]
        
2. **신경망 활용**
    - Q(s, a)를 직접 테이블로 저장하지 않고, **딥러닝 모델**이 Q값을 예측
    - 입력: 상태(예: 이미지 프레임)
    - 출력: 가능한 행동별 Q값
3. **안정성 개선 기법**
    - **경험 재생(Experience Replay)**: 학습 샘플을 버퍼에 저장하고 무작위 추출 → 데이터 상관성 감소
    - **타겟 네트워크(Target Network)**: 일정 주기마다 Q-타겟 계산용 네트워크를 고정 → 학습 안정화

---

## 3. 장점

- 고차원 상태 공간(이미지, 센서 데이터 등) 처리 가능
- 모델이 직접 특징(feature)을 학습하므로 수작업 설계 불필요
- 다양한 RL 문제(게임, 로보틱스)에 적용 가능

---

## 4. 한계

- 샘플 효율 낮음(많은 데이터 필요)
- 불안정한 학습 가능성 → Double DQN, Dueling DQN, Prioritized Replay 등 개선 알고리즘 등장

---

## 5. 대표 응용

- Atari 2600 게임 플레이
- 자율주행 시뮬레이션
- 로봇 제어

---

📌 **암기 포인트**

> DQN = “Q-Learning + Deep Neural Network + Experience Replay + Target Network”
> 

### 문항 22

overfitting vs underfitting

## 1. 개념 비교

| 구분 | Overfitting | Underfitting |
| --- | --- | --- |
| **정의** | 학습 데이터에 너무 과도하게 맞춰져서, 새로운 데이터(테스트셋)에서 성능이 떨어지는 현상 | 학습 데이터에도 충분히 맞추지 못해, 전반적으로 성능이 낮은 현상 |
| **원인** | 모델 복잡도 과도, 학습 데이터에 존재하는 노이즈까지 학습 | 모델이 너무 단순하거나, 학습 부족 |
| **학습 곡선 특징** | 훈련 정확도 ↑, 검증 정확도 ↓ | 훈련 정확도와 검증 정확도 모두 낮음 |
| **비유** | 시험 예상문제만 달달 외움 | 개념 자체를 제대로 이해 못함 |

---

## 2. 특징

### Overfitting

- 훈련 데이터 성능: **매우 높음**
- 검증/테스트 데이터 성능: **낮음**
- 일반화 성능 저하
- 주로 **복잡한 모델**에서 발생 (심층 신경망, 파라미터 수 과다 등)

### Underfitting

- 훈련 데이터 성능: **낮음**
- 검증/테스트 데이터 성능: **더 낮음**
- 학습이 덜 되었거나 모델 용량 부족
- 주로 **단순한 모델**에서 발생 (선형 모델로 복잡한 패턴 학습 시 등)

---

## 3. 해결 방법

### Overfitting 방지

1. **데이터 측면**
    - 데이터 양 늘리기 (수집, 데이터 증강)
    - 노이즈 제거
2. **모델 구조 측면**
    - 모델 단순화 (층 수, 파라미터 수 축소)
    - Dropout, Batch Normalization 적용
3. **학습 과정 측면**
    - 정규화(Regularization) 적용: L1, L2
    - Early Stopping
    - Cross-Validation 활용
4. **앙상블 기법**
    - Bagging, Boosting, Stacking

### Underfitting 방지

1. **모델 복잡도 증가**
    - 더 깊은 신경망, 파라미터 수 증가
2. **학습 과정 개선**
    - 학습 시간(에폭) 늘리기
    - 학습률(Learning Rate) 조정
3. **특징(feature) 강화**
    - 더 구체적이고 유용한 특징 엔지니어링
4. **정규화 약화**
    - L1/L2 계수 줄이기, Dropout 비율 낮추기

---

📌 **암기 팁**

- Overfitting = "Too much memorizing" → 모델 단순화 & 정규화
- Underfitting = "Too simple or too shallow" → 모델 복잡화 & 학습 강화

### 문항 24

https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning

→ 그림이 이거랑 똑같음

## **MLOps Level 0: Manual Process – Key Points**

### 1. **Characteristics**

1. **Fully manual, script-driven**
    - Data analysis → preparation → training → validation are all manual.
    - Often done in notebooks with experimental code by data scientists.
2. **Disconnection between ML and Ops**
    - Data scientists hand off a trained model artifact to engineers for deployment.
    - Engineers prepare production features, risking **training–serving skew**.
        - **Training–serving skew** happens when the data or features your model sees **during training** are different from what it sees **in production (serving)**.
3. **Low release frequency**
    - Model changes/re-training only a few times per year.
4. **No CI/CD**
    - No Continuous Integration: testing happens only within notebooks/scripts.
    - No Continuous Deployment: model deployment is infrequent and manual.
5. **Deployment scope**
    - Focused on serving the model as a prediction service (e.g., REST API), not the entire ML system.
6. **No active performance monitoring**
    - No logging/tracking of predictions → unable to detect drift or degradation.

---

### 2. **Operational Reality**

- Engineering teams still run their own complex API deployment pipeline (security, regression, load, canary testing).
- New models go through A/B testing or online experiments before full rollout.

---

### 3. **Challenges**

- Models degrade in real-world environments due to:
    - Changing data distributions
    - Evolving environment dynamics
- Lack of adaptation and maintenance → model failures in production.

---

### 4. **Recommended Improvements**

1. **Active monitoring**
    - Track performance to detect degradation and drift.
2. **Frequent retraining**
    - Incorporate the latest data (e.g., fashion recommendation adapting to new trends).
3. **Continuous experimentation**
    - Improve features, architecture, hyperparameters.
4. **Introduce CI/CD and CT**
    - **CT (Continuous Training)**: automated re-training pipelines.
    - **CI/CD**: quickly test, build, and deploy new pipeline/model versions.

---

**Exam tip:**

Keywords = *Manual, Script-driven, No CI/CD, Low frequency deploys, No monitoring, Training–Serving skew*

## **MLOps Level 1: ML Pipeline Automation – Key Points**

### 1. **Goal**

- Automate the **ML training pipeline** to enable **Continuous Training (CT)**.
- Use fresh data to retrain and redeploy models automatically.

---

### 2. **Main Characteristics**

1. **Automated orchestration** of ML experiment steps → faster iteration.
2. **CT in production**: Automatic retraining using live data triggers.
3. **Experimental–operational symmetry**: Same pipeline code for dev, pre-prod, and prod environments.
4. **Modularized, containerized components**:
    - Reusable, composable across pipelines.
    - Isolate runtime environments for reproducibility.
5. **Continuous delivery of models**:
    - Trained + validated models are automatically deployed as prediction services.
6. **Pipeline deployment**:
    - Deploy entire training pipeline (not just a model) to run recurrently.

---

### 3. **Additional Components**

- **Data validation**:
    - **Schema skew**: Missing/unexpected features → stop pipeline.
    - **Value skew**: Significant statistical changes → trigger retraining.
- **Model validation**:
    - Compare metrics with current/baseline models.
    - Check performance consistency across data segments.
    - Verify infrastructure compatibility & API consistency.
    - Canary/A/B testing before full rollout.
- **Feature Store (optional)**:
    - Centralized repository for training + serving features.
    - Prevent training–serving skew.
- **Metadata management**:
    - Record pipeline/component versions, parameters, artifacts, metrics.
    - Enable reproducibility, rollback, and debugging.
- **Pipeline triggers**:
    - On demand, scheduled, new data arrival, performance drop, concept drift.

---

### 4. **Challenges**

- If pipeline implementations aren’t updated often and only a few pipelines are managed, manual testing/deployment is still common.
- For frequent changes or many pipelines → need **CI/CD for ML pipelines**.

---

**Exam keywords**:

*Automated CT pipeline, Data/Model validation, Experimental–operational symmetry, Modular components, Feature store, Metadata tracking, Pipeline triggers.*

## **MLOps Level 0 vs Level 1 비교표**

| 구분 | **Level 0: Manual Process** | **Level 1: ML Pipeline Automation** |
| --- | --- | --- |
| **프로세스 방식** | 전 과정 수동, 스크립트·노트북 기반 | 파이프라인 자동화(Orchestration) |
| **ML ↔ Ops 관계** | 데이터 사이언스 팀과 운영팀 분리, 모델 아티팩트 수동 전달 | 개발·운영 환경 동일 파이프라인 사용 (Experimental–Operational Symmetry) |
| **재학습(CT)** | 없음, 연 1~2회 수동 재학습 | 실시간 트리거 기반 자동 재학습 (Continuous Training) |
| **배포 단위** | 학습된 모델만 배포 (예측 서비스) | 전체 학습 파이프라인 배포, 주기적 실행 |
| **CI/CD** | 없음 | 일부 자동화 가능, CT 중심, CI/CD로 확장 가능 |
| **데이터·모델 검증** | 수동, 제한적 | 자동 데이터 검증(스키마·값 편향), 모델 검증(성능 비교·세그먼트별 일관성·배포 전 호환성 테스트) |
| **Feature Store** | 없음 | 선택적으로 사용, 학습–서빙 스큐 방지 |
| **메타데이터 관리** | 제한적, 수동 기록 | 파이프라인 실행·아티팩트·모델 버전·평가 지표 자동 기록 |
| **모니터링** | 거의 없음, 예측·드리프트 추적 부재 | 트리거 조건으로 데이터 분포 변화·성능 저하 감지 가능 |
| **장점** | 간단, 초기 ML 적용에 적합 | 재현성·속도·확장성↑, 새로운 데이터에 빠른 대응 |
| **한계** | 일반화 성능 저하, 운영 환경 적응 어려움 | 많은 파이프라인·새 구현 빈번 시 CI/CD 필요 |

---

📌 **시험 암기 포인트**

- **Level 0** = *Manual, No CI/CD, Model-only deployment, No monitoring*
- **Level 1** = *Automated CT pipeline, Data/Model validation, Metadata tracking, Feature store option*

| 구분 | Level 1 (CT 중심) | CI/CD 완전 자동화 (Level 2) |
| --- | --- | --- |
| **주요 목적** | 새 데이터에 따른 자동 재학습(CT) | 새 코드·구현 변화도 자동 빌드·테스트·배포 |
| **자동화 범위** | 데이터·모델 검증, 모델 배포 자동화 | 데이터·모델 + 파이프라인 코드까지 자동화 |
| **CI (Continuous Integration)** | 거의 없음 또는 수동 | 코드 변경 시 자동 빌드·테스트 |
| **CD (Continuous Delivery/Deployment)** | 모델 배포 일부 자동화 | 전체 ML 시스템(파이프라인 포함) 자동 배포 |
| **대상 변경 요소** | 데이터 변화 | 데이터 + 코드/구현 변화 모두 |
| **적합 상황** | 데이터 변화 주기가 빠르지만 코드 변경은 드문 경우 | 데이터·코드 변경 모두 빈번한 경우 |

📌 **정리**

- **Level 1** → "데이터 변화"에 맞춰 모델을 **자동 재학습 + 배포**하는 단계.
- **Level 2** → 데이터 변화뿐 아니라 **코드·구현 변경**까지 포함해 **CI/CD 전면 자동화**.

## **MLOps Level 2 – CI/CD Pipeline Automation**

**Goal:**

Enable rapid and reliable pipeline updates in production by fully automating build, test, and deployment with CI/CD, allowing fast experimentation and delivery of new ML ideas.

### **Key Characteristics**

- **Full Automation:** Combines Level 1’s automated ML pipeline (CT) with CI/CD for code and pipeline updates.
- **Stages:**
    1. **Development & Experimentation** – Try new algorithms, architectures, features; push source code to repository.
    2. **Pipeline CI** – Build, unit/integration test pipeline components (packages, containers, executables).
    3. **Pipeline CD** – Deploy new pipeline implementation to target environment.
    4. **Automated Triggering** – Run pipeline based on schedule or events.
    5. **Model CD** – Deploy trained model as prediction service.
    6. **Monitoring** – Track model performance, trigger retraining or new experiments.
- **Validation:** Data, model performance, API compatibility, and serving performance are automatically tested before deployment.
- **Deployment Strategy:** Gradual rollout (dev → pre-prod → prod) with automated and semi-automated steps.

### **Benefits**

- Rapid iteration and deployment of both data-driven changes and code-driven improvements.
- Reduced risk of production issues through automated testing.
- Faster adaptation to data drift, concept drift, and evolving business needs.

| 구분 | **Level 0** – Manual Process | **Level 1** – ML Pipeline Automation | **Level 2** – CI/CD Pipeline Automation |
| --- | --- | --- | --- |
| **프로세스** | 전 과정 수동 실행 (데이터 준비, 학습, 검증, 배포) | 파이프라인 단계 자동화, 지속적 학습(CT) 가능 | 파이프라인 자동화 + CI/CD로 코드·파이프라인 자동 테스트·배포 |
| **자동화 범위** | 없음 | 데이터 처리·모델 학습·검증 자동화 | 소스 코드 빌드·테스트·배포 자동화까지 포함 |
| **연속 학습(CT)** | X | O (스케줄/트리거 기반) | O (CT + 코드 변경 시 자동 반영) |
| **CI (지속적 통합)** | X | X | O (코드 커밋 시 빌드·테스트 자동 실행) |
| **CD (지속적 배포)** | X | 모델 배포 자동화만 | O (모델·파이프라인 배포 모두 자동화) |
| **배포 단위** | 모델 아티팩트 | 전체 학습 파이프라인 | 전체 파이프라인 + 모델 예측 서비스 |
| **데이터·모델 검증** | 수동 | 자동 데이터 검증·모델 성능 검증 | 자동 검증 + 성능/호환성 테스트 |
| **특징적 컴포넌트** | 없음 | 파이프라인 오케스트레이터, 데이터·모델 검증, (옵션) 피처 스토어 | Level 1 구성 + 소스 컨트롤, 빌드/테스트 서비스, 배포 서비스, 모델 레지스트리 |
| **배포 속도** | 매우 느림 (연 1~2회) | 중간 (데이터 변화 시 자동 학습·배포) | 매우 빠름 (데이터·코드 변화 모두 자동 반영) |
| **운영 모니터링** | 없음 | 모델 성능 모니터링 O | 모델 + 파이프라인 모니터링 O |
| **적합한 상황** | 모델 변경·재학습 거의 없는 초기 단계 | 데이터 변화에 자주 대응해야 하는 경우 | 데이터·코드 모두 자주 변경되는 고도화 환경 |