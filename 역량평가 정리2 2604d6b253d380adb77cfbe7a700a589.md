# 역량평가 정리2

## ✅ 정규화(Normalization)와 표준화(Standardization) 개념 정리

- **정규화 (Normalization, Min-Max Scaling)**
    - 데이터를 **0~1 범위(또는 특정 구간)**로 변환하는 과정.
    - 계산식:
        
        x′=x−xminxmax−xminx' = \frac{x - x_{min}}{x_{max} - x_{min}}
        
    - 특징: 값의 범위가 일정하게 제한됨. 이상치(Outlier)에 민감하여 최소값/최대값이 크게 변하면 전체 스케일에 영향을 줌.
- **표준화 (Standardization, Z-score Scaling)**
    - 데이터를 평균 0, 표준편차 1을 가지도록 변환하는 과정.
    - 계산식:
        
        x′=x−μσx' = \frac{x - \mu}{\sigma}
        
    - 특징: 정규분포 가정이 필요한 통계 분석이나 알고리즘(PCA, 회귀분석, SVM 등)에 자주 사용됨. 이상치의 영향을 상대적으로 덜 받음.

## ✅ Vision 영역 데이터 증강 기법 개념 정리

- **Gaussian Blur**
    - 이미지를 부드럽게 만들기 위해 픽셀을 주변 픽셀과 평균화하여 경계를 흐리게 하는 방법.
    - 세부 사항을 감소시켜 모델이 작은 잡음에 덜 민감해지도록 하지만, 세밀한 분할(예: Semantic Segmentation)에는 불리할 수 있음.
- **ADASYN (Adaptive Synthetic Sampling Approach)**
    - 소수 클래스의 표본을 자동으로 합성하여 불균형 데이터 문제를 해결하는 오버샘플링 기법.
    - Vision 영역에서 직접적인 픽셀 단위 증강보다는 클래스 균형을 맞추는 데 사용됨.
- **Random Erasing**
    - 이미지의 일부분을 무작위로 가리거나 삭제하여 불완전한 정보를 학습하도록 하는 증강 기법.
    - 실제 환경에서 발생할 수 있는 가림, 노이즈, 장애물을 모델이 견디도록 훈련하는 데 유용.
- **Mixup**
    - 두 개 이상의 이미지를 섞어 새로운 학습 데이터를 생성하는 방법.
    - 분류(Classification) 문제에서 일반화 성능을 높이는 데 효과적이나, 정확한 픽셀 레벨 분할(Segmentation)에서는 부적합.
- **SMOTE (Synthetic Minority Over-sampling Technique)**
    - ADASYN과 유사하게 소수 클래스 데이터를 합성하는 기법.
    - Vision 영역에서 이미지 단위 데이터 증강보다는 불균형 클래스 해결 목적으로 주로 사용됨.

## ✅ 그래프 데이터 증강 기법 개념 정리

1. **Node Dropout**
    - 일부 노드를 제거하여 학습 시 특정 노드에 대한 의존도를 낮추는 방법.
    - 모델이 특정 중심 노드에 과도하게 의존하지 않도록 하여 일반화 성능을 높임.
2. **Edge Dropout**
    - 일부 엣지를 제거하여 연결 구조를 변화시키는 방법.
    - 모델이 다양한 연결 패턴을 학습하게 만들어 **강건성(Robustness)**을 향상시킴.
3. **Node Feature Masking**
    - 노드의 일부 속성(feature)을 가리거나 제거하는 방식.
    - 모델이 특정 feature에만 의존하지 않도록 하여 과적합을 방지하고 일반화 성능을 높임.
4. **Edge Rewiring**
    - 기존 그래프의 엣지를 재구성하거나 일부 엣지를 무작위로 교체하는 방법.
    - 새로운 구조적 변화를 반영하여 모델이 더 다양한 그래프 패턴을 학습할 수 있게 함.
5. **Subgraph Sampling**
    - 전체 그래프에서 일부 서브그래프를 샘플링하여 학습에 사용하는 방법.
    - 대규모 그래프에서도 계산 효율성을 높이고, 특정 부분 구조를 강조하는 효과.

# 📘 Diffusion Model 한 장 요약 노트

## 1. 기본 아이디어

- 데이터에 점차 **노이즈를 주입(Forward Process)** → 완전한 가우시안 노이즈 도달
- 노이즈에서 시작해 **조금씩 제거(Backward Process)** → 원본 데이터 복원
- 학습 목표: **Backward Process 근사** (Forward는 고정되어 최적화 대상 아님)

---

## 2. Forward Process (전향 과정)

- 원본 데이터 → 점차 노이즈 추가
- 수식:

q(xt∣xt−1)=N(xt;1−βtxt−1,βtI)q(x_t | x_{t-1}) = \mathcal{N}(x_t ; \sqrt{1-\beta_t} x_{t-1}, \beta_t I)

- 누적:

xt=αtˉx0+1−αtˉϵx_t = \sqrt{\bar{\alpha_t}} x_0 + \sqrt{1 - \bar{\alpha_t}} \epsilon

(αtˉ=∏s=1t(1−βs)\bar{\alpha_t} = \prod_{s=1}^t (1-\beta_s))

- **특징**: 고정된 과정, 학습 X

---

## 3. Backward Process (역확산 과정)

- 노이즈 → 원본 데이터 복원
- 학습 모델 pθ(xt−1∣xt)p_\theta(x_{t-1}|x_t)이 역과정을 근사
- 손실 함수:

L(θ)=Ex0,ϵ,t[∥ϵ−ϵθ(xt,t)∥2]L(\theta) = \mathbb{E}_{x_0, \epsilon, t}\big[ \| \epsilon - \epsilon_\theta(x_t, t) \|^2 \big]

- **특징**: 학습 대상(최적화 O), MSE 기반

---

## 4. 장단점

✅ 장점

- 학습 안정적 (GAN보다 모드 붕괴 없음)
- 초고품질 이미지, 텍스트-이미지 합성 (Stable Diffusion, Imagen, DALL·E 2 등)
- 다양한 데이터 도메인(이미지, 오디오, 텍스트, 과학 데이터) 적용 가능

❌ 단점

- 샘플링 속도 느림 (수십~수천 단계 필요)

---

## 5. GAN과 비교

---

## 6. 응용 사례

| 구분 | **GAN** | **Diffusion Model** |
| --- | --- | --- |
| 학습 방식 | Generator ↔ Discriminator 적대적 학습 | Forward 고정, Backward 근사 학습 |
| 안정성 | 불안정, 모드 붕괴 발생 | 안정적 (확률적 손실 기반) |
| 생성 속도 | 빠름 (한 번의 Forward Pass) | 느림 (여러 step 필요) |
| 품질 | 과거엔 우수했지만 한계 | 현재 최고 수준(SOTA) |
| 대표 모델 | StyleGAN, BigGAN | DDPM, DDIM, Stable Diffusion |
- **이미지 합성**: Stable Diffusion, DALL·E 2
- **텍스트-이미지 생성**: Prompt 기반 생성
- **음성 합성**: WaveGrad
- **과학**: 단백질 구조 예측, 신약 개발

---

# ✅ 핵심 요약

- Forward = 노이즈 추가 (고정, 학습 X)
- Backward = 노이즈 제거 (학습 O, 최적화 대상)
- GAN 대비: 안정성 ↑, 속도 ↓, 품질 ↑
- 대표 응용: Stable Diffusion

# 📘 GAN (Generative Adversarial Network) 개념 정리

## 1. 기본 아이디어

- **2014년 Goodfellow**가 제안한 대표적인 생성 모델.
- 두 개의 네트워크가 경쟁적으로 학습 (**Adversarial Training**):
    - **Generator (G)**: 랜덤 노이즈 → 가짜 데이터 생성
    - **Discriminator (D)**: 입력이 진짜 데이터인지 가짜 데이터인지 판별
- Generator는 Discriminator를 속이려고 하고, Discriminator는 이를 구별하려고 학습 → 경쟁(Zero-sum game).

---

## 2. 학습 과정

- 목표: Generator가 만든 가짜 데이터 분포가 실제 데이터 분포와 거의 동일해지도록 함.
- 손실 함수(최소-최대 문제):

min⁡Gmax⁡DV(D,G)=Ex∼pdata(x)[log⁡D(x)]+Ez∼pz(z)[log⁡(1−D(G(z)))]\min_G \max_D V(D,G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log (1 - D(G(z)))]

---

## 3. 장점

✅ 매우 빠른 샘플 생성 (한 번의 Forward Pass로 결과 출력)

✅ 이미지 생성, 변환(Style Transfer), 슈퍼 해상도 등 다양한 응용

✅ 한때 이미지 생성에서 최고의 성능 달성 (StyleGAN, BigGAN 등)

---

## 4. 단점

❌ 학습 불안정 (Generator ↔ Discriminator 균형 붕괴 가능)

❌ **Mode Collapse**: Generator가 데이터 다양성을 잃고 일부 샘플만 반복 생성

❌ Hyperparameter 민감

---

## 5. 대표 응용 모델

- **StyleGAN**: 사람 얼굴, 예술적 이미지 생성
- **CycleGAN**: 이미지 변환 (예: 말 ↔ 얼룩말, 낮 ↔ 밤)
- **Pix2Pix**: 조건부 이미지 변환

---

# 📘 Diffusion Model vs GAN 요약 비교

| 구분 | **GAN** | **Diffusion Model** |
| --- | --- | --- |
| 학습 방식 | Generator ↔ Discriminator 적대적 학습 | Forward Process(고정) + Backward Process 학습 |
| 학습 안정성 | 불안정, Mode Collapse 발생 가능 | 안정적 (노이즈 예측 기반 손실) |
| 최적화 대상 | G와 D 동시에 학습 | Backward Process만 학습 |
| 생성 속도 | 빠름 (1 step) | 느림 (수십~수천 step) |
| 품질 | 과거 최고, 현재는 한계 | 초고품질 (SOTA) |
| 대표 모델 | StyleGAN, BigGAN, CycleGAN | DDPM, DDIM, Stable Diffusion, Imagen |
| 응용 | 이미지 생성·변환, 영상, 해상도 향상 | 이미지·텍스트·음성 합성, 과학(단백질/신약) |

---

# ✅ 핵심 요약

- **GAN**: 빠르지만 학습 불안정, Mode Collapse 문제 있음.
- **Diffusion Model**: 느리지만 학습 안정적, 품질 최고.
- 현재는 **Diffusion이 SOTA**(Stable Diffusion, Imagen, DALL·E 2 등),
    
    그러나 GAN은 여전히 **실시간 생성·영상 처리** 등에서 강점 있음.
    

# ✅ Self-Supervised Learning 관련 개념 정리

### 1. **SimCLR**

- **Contrastive Learning** 기반 대표 기법.
- 동일한 이미지에서 다른 변환(Augmentation)을 적용한 두 샘플을 **Positive pair**, 다른 이미지들을 **Negative pair**로 설정.
- **Loss:** Positive는 가깝게, Negative는 멀리 보내도록 학습.
- InfoNCE loss 사용.

---

### 2. **BYOL (Bootstrap Your Own Latent)**

- Contrastive learning과 달리 **Negative sample이 필요 없음**.
- 두 네트워크 구조:
    - **Online network**: 일반적인 gradient descent로 업데이트.
    - **Target network**: Online network 파라미터를 EMA(Exponential Moving Average)로 업데이트.
- 자기 자신을 bootstrap 하여 representation 학습.

---

### 3. **Jigsaw Puzzle**

- 이미지를 여러 조각으로 나눈 뒤 **무작위로 섞음**.
- 원래 순서를 맞추도록 학습하여 **공간적 구조(Spatial structure)**를 학습.
- 초기 SSL에서 자주 쓰인 Pretext task.

---

### 4. **MAE (Masked AutoEncoder)**

- 입력 이미지의 일부 패치를 가림(Masking).
- **Encoder**: 남아 있는 패치로 latent representation 생성.
- **Decoder**: 마스킹된 패치를 복원하도록 학습.
- NLP의 BERT에서 아이디어 차용 → 이미지 복원형 SSL 기법.

---

### 5. **RotNet**

- 입력 이미지를 여러 각도로 회전(0°, 90°, 180°, 270°).
- 네트워크가 회전된 각도를 맞추도록 학습.
- 이미지의 전역적 특징(Global feature)을 학습하는 단순하지만 효과적인 방법.

- **Pretext Task 기반 SSL**: 사람이 직접 라벨링한 supervised label 대신, **인위적인 작은 과제를 만들어 학습하는 방식**
    - Jigsaw Puzzle → 이미지 조각 순서 맞추기
    - RotNet → 이미지 회전 각도 맞추기
    - MAE → 이미지 패치 마스킹 후 복원
- **Contrastive Learning 기반 SSL**: 서로 다른 샘플의 representation 관계를 학습하는 방식
    - 대표: SimCLR, MoCo, BYOL 등
    - Positive/Negative 관계를 통해 representation space를 정렬

# 🔎 하이퍼파라미터 탐색 기법 정리

## 1️⃣ 그리드 탐색 (Grid Search)

- **개념**: 미리 정해둔 하이퍼파라미터 후보 값들의 **모든 조합을 전수 조사**하는 방법.
- **특징**:
    - 탐색 공간이 작을 때는 유용.
    - 최적값을 찾을 확률이 높음.
    - 하지만 파라미터가 많아지면 조합이 기하급수적으로 늘어나 **비효율적**.
- **비유**: "체계적으로 바둑판처럼 모든 칸을 다 확인하는 방식."

---

## 2️⃣ 랜덤 탐색 (Random Search)

- **개념**: 탐색 공간에서 **무작위로 하이퍼파라미터 조합을 샘플링**하여 탐색하는 방법.
- **특징**:
    - 계산량을 줄일 수 있어 고차원(변수가 많은 경우)에서 효과적.
    - 반드시 최적값을 찾는다는 보장은 없음.
    - 하지만 실제 연구에서는 그리드 탐색보다 효율적인 경우가 많음 (특히 일부 하이퍼파라미터가 모델 성능에 훨씬 중요한 경우).
- **비유**: "무작위로 여기저기 찍어보면서 효율적으로 좋은 결과를 찾는 방식."

---

## 3️⃣ 베이지안 탐색 (Bayesian Optimization)

- **개념**: 단순히 무작정 탐색하는 게 아니라, **이전 탐색 결과를 확률 모델(보통 가우시안 프로세스 등)에 반영**하여 앞으로 더 탐색할 후보를 똑똑하게 선택하는 방법.
- **특징**:
    - 탐색 과정에서 얻은 성능 정보를 활용 → 점점 더 좋은 후보를 제시.
    - 그리드/랜덤 탐색보다 훨씬 **적은 시도로 좋은 결과**를 얻을 수 있음.
    - 구현이 복잡하고 연산량이 많을 수 있음.
- **비유**: "앞에서 얻은 힌트를 바탕으로 점점 더 유망한 지점을 공략하는 방식."

---

# 📊 비교 정리 표

| 방법 | 탐색 방식 | 장점 | 단점 | 적합한 상황 |
| --- | --- | --- | --- | --- |
| **그리드 탐색** | 모든 조합 전수조사 | 최적값 찾을 확률 높음 | 계산량 많음 (비효율적) | 파라미터 수가 적고 범위가 작은 경우 |
| **랜덤 탐색** | 무작위 샘플링 | 효율적, 계산 비용 낮음 | 최적값 보장 없음 | 고차원 파라미터, 빠른 실험 필요할 때 |
| **베이지안 탐색** | 이전 결과를 활용해 확률적으로 탐색 | 효율적으로 좋은 값 찾음 | 구현 복잡, 계산량 부담 | 탐색 비용이 큰 모델(딥러닝, 대규모 ML) |

---

👉 정리하면:

- **그리드 탐색**: 전수조사 (작은 공간에서만 현실적).
- **랜덤 탐색**: 무작위 탐색 (효율적, 고차원에 유리).
- **베이지안 탐색**: 학습 기반 탐색 (적은 시도로 좋은 성능).

# 🔎 모델 배포 방식 정리

## 1️⃣ Model-in-service

- **개념**: 모델을 애플리케이션 서버(웹 서버, API 서버 등)에 직접 포함하여 함께 배포하는 방식.
    
    → 웹 서버 코드와 모델 코드가 한 서버에서 같이 동작.
    

### ✅ 장점

- **기존 인프라 재사용 가능** → 별도의 모델 서버 구축 불필요.
- 배포 구조 단순 → 설정, 네트워킹 관리가 쉬움.
- 클라이언트 → 서버 → 모델까지 경로가 짧아서 레이턴시(지연 시간)가 낮을 수 있음.

### ❌ 단점

- 서버 자원이 **웹 요청 처리 + 모델 추론**에 동시에 사용되어 부담 증가.
- 서버 확장(스케일링) 시 모델도 같이 복제되므로 **비효율적**.
- 모델 변경 시 전체 서버 재배포 필요.

---

## 2️⃣ Model-as-service

- **개념**: 모델을 별도의 서버(또는 클라우드 서비스)로 분리하여 API 형태로 제공하는 방식.
    
    → 애플리케이션 서버는 모델 서버에 요청을 보내고 응답을 받음.
    

### ✅ 장점

- **확장성 우수** → 모델 서버만 따로 확장 가능.
- 모델 변경/배포가 웹 서버와 독립적 → 유지보수 편리.
- 여러 애플리케이션에서 **공용 모델 서버**를 호출 가능.

### ❌ 단점

- 네트워크를 통한 요청/응답 필요 → 레이턴시가 증가할 수 있음.
- 별도 인프라(모델 서버, 클라우드 등) 필요 → 관리 복잡성↑.
- 초기 구축 비용이 상대적으로 큼.

---

# 📊 비교 표

| 구분 | **Model-in-service** | **Model-as-service** |
| --- | --- | --- |
| **구조** | 웹 서버 안에 모델 포함 | 모델을 독립 서버/API로 분리 |
| **장점** | 기존 인프라 재사용, 배포 단순, 낮은 지연 시간 | 확장성 높음, 유지보수 편리, 여러 서비스에서 재사용 가능 |
| **단점** | 자원 부담 ↑, 확장 비효율적, 모델 변경 시 전체 재배포 | 네트워크 지연 ↑, 별도 인프라 필요, 관리 복잡 |
| **적합한 상황** | 소규모 시스템, 단일 서버 서비스 | 대규모 서비스, 다수 애플리케이션에서 공용 모델 활용 |

---

👉 정리하면:

- **작고 단순한 서비스 → Model-in-service**
- **확장성과 유지보수가 중요한 대규모 서비스 → Model-as-service**

## 🔹 Feature Store

- **개념**: 모델 학습(training)과 추론(inference)에서 사용하는 **피처(feature)를 저장, 관리, 제공**하는 시스템.
- **주요 목적**:
    - 학습과 추론 시 일관된 피처 제공 (Train-Serving Skew 방지).
    - 배치(batch)와 실시간(real-time) 피처를 모두 지원.
    - 피처를 재사용하고 공유할 수 있어 개발 생산성 향상.
- **한계**: 레이블 자동 생성 같은 기능은 제공하지 않음.

---

## 🔹 모델 버저닝 (Model Versioning)

- **개념**: 모델이 학습된 버전을 추적하고 관리하는 방법.
- **주요 목적**:
    - 모델 간 성능 비교와 재현성 확보.
    - 데이터셋과 모델을 연계 관리 가능 (예: MLflow, DVC).
- **한계**: 동일 버전이라도 학습 환경·랜덤 초기화 차이로 인해 결과가 항상 동일하다고 보장할 수는 없음.
- 특정 시점의 모델 성능, 학습 데이터, 하이퍼파라미터를 추적 가능.

---

## 🔹 모델 모니터링 (Model Monitoring)

- **개념**: 배포된 모델의 동작 상태와 성능을 지속적으로 추적하는 과정.
- **필요 이유**:
    - 데이터 드리프트(Data Drift), 개념 드리프트(Concept Drift) 감지.
    - 모델 성능 저하 추적.
    - 리소스 사용량 추적(예: CPU/GPU, 메모리).
- **한계**: 모델 아키텍처를 자동으로 변경하는 기능은 포함되지 않음.

---

## 🔹 Serverless 아키텍처 (FaaS: Function as a Service)

- **개념**: 서버를 직접 관리하지 않고, 함수 단위로 실행 환경을 클라우드가 자동 제공하는 구조. (예: AWS Lambda, Google Cloud Functions)
- **장점**:
    - 요청이 적으면 비용 절감 (pay-per-use).
    - 필요 시 자동 확장.
    - 서버 관리가 단순해짐.
- **단점**:
    - Cold Start 지연 발생 → 특히 추론 요청이 많을 때 성능 저하 우려.
    - 장시간 실행되는 작업에는 부적합.

---

## 🔹 멀티모델 서빙 (Multi-Model Serving)

- **개념**: 여러 개의 AI 모델을 하나의 서버 인스턴스나 프로세스에서 동시에 운영하는 방식.
- **장점**:
    - 리소스를 공유하여 비용 절감 가능 (GPU/메모리 효율적 사용).
    - 소규모 모델 여러 개를 동시에 관리 가능.
    - 일부 모델 교체나 업데이트도 비교적 유연.
- **한계/주의점**:
    - 자원 경쟁(resource contention) 문제 발생 가능.
    - 성능 최적화를 위해 모델 크기·로드 전략 고려 필요.

---

✅ 정리하면,

- **Feature Store** → 피처 일관성 & 재사용성 관리.
- **모델 버저닝** → 모델 버전 추적·비교·재현성.
- **모델 모니터링** → 성능·데이터 변화·리소스 추적.
- **Serverless** → 관리 단순·비용 효율 vs Cold Start 문제.
- **멀티모델 서빙** → 자원 효율적 활용 vs 자원 경쟁 관리 필요.

---

# 🔎 Compound Scaling 개념 정리

## 1️⃣ 기존 Scaling 방식

- **Depth scaling**: 층(layer) 수를 늘려 네트워크를 깊게 만듦 → 더 복잡한 표현 학습 가능.
- **Width scaling**: 각 층의 채널 수를 늘려 네트워크를 넓게 만듦 → 세부적 패턴 포착 능력 향상.
- **Resolution scaling**: 입력 이미지 해상도를 키움 → 더 많은 세부 정보 활용 가능.

👉 하지만 각각을 단독으로 키우면 **효율성이 떨어지고 성능 개선이 제한적**임.

---

## 2️⃣ Compound Scaling 방식

EfficientNet은 다음 아이디어를 도입:

- 세 가지 요소를 **균형 있게 동시에 확장**.
- 단일 계수 φ(phi)를 두고, **depth, width, resolution**을 각각의 계수에 맞게 함께 늘림.

공식:

depth:d=αϕ,width:w=βϕ,resolution:r=γϕdepth : d = \alpha^\phi, \quad width : w = \beta^\phi, \quad resolution : r = \gamma^\phi

depth:d=αϕ,width:w=βϕ,resolution:r=γϕ

단,

α⋅β2⋅γ2≈2,α≥1,β≥1,γ≥1\alpha \cdot \beta^2 \cdot \gamma^2 \approx 2, \quad \alpha \geq 1, \beta \geq 1, \gamma \geq 1

α⋅β2⋅γ2≈2,α≥1,β≥1,γ≥1

- **φ (phi)**: 전체 리소스 증가 비율 (예: 연산량 2배로 증가).
- **α, β, γ**: 각각 depth, width, resolution의 비율.
- 목적: **성능과 효율성을 동시에 극대화**.

---

## 3️⃣ 핵심 포인트

- 단일 scaling(너비만 키우거나, 해상도만 키우는 것)보다 훨씬 효율적.
- 동일한 연산량 대비 더 높은 정확도를 달성.
- EfficientNet-B0 ~ B7 모델들이 이 방식으로 생성됨.